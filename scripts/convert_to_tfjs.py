#!/usr/bin/env python3
"""
æ¨¡å‹è½¬æ¢è„šæœ¬ï¼šPyTorch â†’ TensorFlow.js
å°†è®­ç»ƒå¥½çš„ResNet18æ¨¡å‹è½¬æ¢ä¸ºWebå¯ç”¨çš„TensorFlow.jsæ ¼å¼
"""

import os
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models
import json
import subprocess
import argparse
from pathlib import Path

class L2Norm(nn.Module):
    """L2æ ‡å‡†åŒ–å±‚"""
    def __init__(self, dim=1):
        super(L2Norm, self).__init__()
        self.dim = dim
        
    def forward(self, x):
        return F.normalize(x, p=2, dim=self.dim)

class ResNet18Contrastive(nn.Module):
    """æ”¯æŒå¯¹æ¯”å­¦ä¹ çš„ResNet18æ¨¡å‹"""
    
    def __init__(self, num_classes, embedding_dim=128):
        super(ResNet18Contrastive, self).__init__()
        
        # åŠ è½½é¢„è®­ç»ƒçš„ResNet18
        self.backbone = models.resnet18(pretrained=True)
        
        # æ›´æ¿€è¿›çš„è§£å†»ç­–ç•¥ï¼šè§£å†»æ›´å¤šå±‚ä»¥æé«˜å­¦ä¹ èƒ½åŠ›
        for param in self.backbone.parameters():
            param.requires_grad = False
        
        # è§£å†»åé¢å‡ å±‚ç”¨äºå¾®è°ƒ
        for name, param in self.backbone.named_parameters():
            if 'layer4' in name or 'layer3' in name or 'layer2' in name:
                param.requires_grad = True
        
        # è·å–ç‰¹å¾ç»´åº¦ï¼ˆåœ¨ç§»é™¤åˆ†ç±»å™¨ä¹‹å‰ï¼‰
        num_features = self.backbone.fc.in_features
        
        # ç§»é™¤åŸå§‹åˆ†ç±»å™¨
        self.backbone.fc = nn.Identity()
        
        # æ·»åŠ ç‰¹å¾åµŒå…¥å±‚ - å®Œå…¨åŒ¹é…è®­ç»ƒè„šæœ¬æ¶æ„
        self.embedding = nn.Sequential(
            nn.Linear(num_features, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, embedding_dim),
            L2Norm(dim=1)  # L2æ ‡å‡†åŒ–ç”¨äºå¯¹æ¯”å­¦ä¹ 
        )
        
        # åˆ†ç±»å¤´ - å®Œå…¨åŒ¹é…è®­ç»ƒè„šæœ¬æ¶æ„
        self.classifier = nn.Sequential(
            nn.Linear(embedding_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256, num_classes)
        )
        
        # L2æ ‡å‡†åŒ–
        self.l2_norm = lambda x: F.normalize(x, p=2, dim=1)
    
    def forward(self, x):
        features = self.backbone(x)
        embeddings = self.embedding(features)
        
        if self.training:
            # è®­ç»ƒæ—¶è¿”å›åµŒå…¥å‘é‡å’Œåˆ†ç±»ç»“æœ
            classification = self.classifier(embeddings)
            return embeddings, classification
        else:
            # æ¨ç†æ—¶åªè¿”å›åˆ†ç±»ç»“æœ
            return self.classifier(embeddings)

def load_pytorch_model(model_path, num_classes=10):
    """åŠ è½½PyTorchæ¨¡å‹ - è‡ªåŠ¨æ£€æµ‹æ¨¡å‹ç±»å‹å’Œå‚æ•°"""
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    checkpoint = torch.load(model_path, map_location='cpu')
    state_dict = checkpoint['model_state_dict']
    
    # æ£€æµ‹æ¨¡å‹ç±»å‹ï¼šæ˜¯å¦åŒ…å«å¯¹æ¯”å­¦ä¹ ç»“æ„
    is_contrastive = any('backbone.' in key or 'embedding.' in key for key in state_dict.keys())
    
    if is_contrastive:
        print("æ£€æµ‹åˆ°å¯¹æ¯”å­¦ä¹ æ¨¡å‹ï¼ŒåŠ è½½ResNet18Contrastive...")
        
        # ä»æƒé‡è‡ªåŠ¨æ£€æµ‹embedding_dim
        embedding_dim = 128  # é»˜è®¤å€¼
        for key in state_dict.keys():
            if 'embedding.3.weight' in key:  # embeddingæœ€åä¸€å±‚çš„æƒé‡
                embedding_dim = state_dict[key].shape[0]
                print(f"æ£€æµ‹åˆ°embedding_dim: {embedding_dim}")
                break
        
        model = ResNet18Contrastive(num_classes, embedding_dim=embedding_dim)
    else:
        print("æ£€æµ‹åˆ°æ ‡å‡†åˆ†ç±»æ¨¡å‹ï¼ŒåŠ è½½æ ‡å‡†ResNet18...")
        # åˆ›å»ºæ ‡å‡†æ¨¡å‹ç»“æ„
        model = models.resnet18(pretrained=False)
        num_features = model.fc.in_features
        model.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(num_features, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )
    
    # åŠ è½½æƒé‡
    model.load_state_dict(state_dict)
    model.eval()
    
    return model, checkpoint.get('class_names', [f'ID_{i+1}' for i in range(num_classes)])

def convert_to_onnx(model, onnx_path):
    """è½¬æ¢ä¸ºONNXæ ¼å¼"""
    
    print("æ­£åœ¨è½¬æ¢ä¸ºONNXæ ¼å¼...")
    
    # åˆ›å»ºè™šæ‹Ÿè¾“å…¥
    dummy_input = torch.randn(1, 3, 224, 224)
    
    # å¯¼å‡ºONNX
    torch.onnx.export(
        model,
        dummy_input,
        onnx_path,
        export_params=True,
        opset_version=11,
        do_constant_folding=True,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={
            'input': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        }
    )
    
    print(f"ONNXæ¨¡å‹å·²ä¿å­˜åˆ°: {onnx_path}")

def convert_onnx_to_tensorflow(onnx_path, tf_output_path):
    """è½¬æ¢ONNXåˆ°TensorFlow SavedModelæ ¼å¼"""
    try:
        print("æ­£åœ¨è½¬æ¢ONNXåˆ°TensorFlow...")
        
        # ä½¿ç”¨onnx-tfè½¬æ¢ONNXåˆ°TensorFlow SavedModel
        import onnx
        from onnx_tf.backend import prepare
        
        # åŠ è½½ONNXæ¨¡å‹
        onnx_model = onnx.load(onnx_path)
        
        # è½¬æ¢ä¸ºTensorFlowæ ¼å¼
        tf_rep = prepare(onnx_model)
        
        # ä¿å­˜ä¸ºSavedModelæ ¼å¼
        tf_rep.export_graph(tf_output_path)
        
        print(f"TensorFlow SavedModelå·²ä¿å­˜åˆ°: {tf_output_path}")
        return True
        
    except Exception as e:
        print(f"è½¬æ¢å¤±è´¥: {e}")
        print("æç¤º: è¯·ç¡®ä¿å®‰è£…äº†å…¼å®¹ç‰ˆæœ¬çš„onnx-tf")
        return False

def convert_to_tfjs(tf_path, tfjs_path):
    """è½¬æ¢TensorFlow SavedModelåˆ°TensorFlow.jsæ ¼å¼"""
    try:
        print("æ­£åœ¨è½¬æ¢TensorFlowåˆ°TensorFlow.js...")
        
        # ä½¿ç”¨tensorflowjs_converterè½¬æ¢SavedModelåˆ°TensorFlow.js
        result = subprocess.run([
            'tensorflowjs_converter',
            '--input_format=tf_saved_model',
            '--output_format=tfjs_graph_model',
            '--strip_debug_ops=True',
            '--quantize_float16=True',
            tf_path,
            tfjs_path
        ], capture_output=True, text=True, timeout=600)
        
        if result.returncode != 0:
            raise Exception(result.stderr)
            
        print(f"TensorFlow.jsæ¨¡å‹å·²ä¿å­˜åˆ°: {tfjs_path}")
        return True
        
    except Exception as e:
        print(f"è½¬æ¢å¤±è´¥: {e}")
        return False

def create_model_metadata(class_names, tfjs_path):
    """åˆ›å»ºæ¨¡å‹å…ƒæ•°æ®"""
    
    metadata = {
        "model_name": "ResNet18 Identity Classifier",
        "model_version": "1.0.0",
        "description": "åŸºäºResNet18çš„å…»è€é™¢èº«ä»½è¯†åˆ«åˆ†ç±»å™¨",
        "input_shape": [1, 224, 224, 3],
        "output_shape": [1, len(class_names)],
        "num_classes": len(class_names),
        "class_names": class_names,
        "class_mapping": {i: name for i, name in enumerate(class_names)},
        "preprocessing": {
            "resize": [224, 224],
            "normalize": {
                "mean": [0.485, 0.456, 0.406],
                "std": [0.229, 0.224, 0.225]
            }
        },
        "usage": {
            "strict_consistency_check": True,
            "required_images": 3,
            "confidence_threshold": 0.7,
            "time_permissions": {
                "staff": "24h",
                "resident": "06:30-20:30"
            }
        }
    }
    
    # ä¿å­˜å…ƒæ•°æ®
    metadata_path = os.path.join(tfjs_path, 'metadata.json')
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    print(f"æ¨¡å‹å…ƒæ•°æ®å·²ä¿å­˜åˆ°: {metadata_path}")

def validate_tfjs_model(tfjs_path):
    """éªŒè¯TensorFlow.jsæ¨¡å‹"""
    
    print("æ­£åœ¨éªŒè¯TensorFlow.jsæ¨¡å‹...")
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    required_files = ['model.json']
    for file_name in required_files:
        file_path = os.path.join(tfjs_path, file_name)
        if not os.path.exists(file_path):
            print(f"é”™è¯¯: ç¼ºå°‘æ–‡ä»¶ {file_name}")
            return False
    
    # æ£€æŸ¥æƒé‡æ–‡ä»¶
    weight_files = [f for f in os.listdir(tfjs_path) if f.endswith('.bin')]
    if not weight_files:
        print("é”™è¯¯: ç¼ºå°‘æƒé‡æ–‡ä»¶ (.bin)")
        return False
    
    # è¯»å–æ¨¡å‹é…ç½®
    model_json_path = os.path.join(tfjs_path, 'model.json')
    try:
        with open(model_json_path, 'r') as f:
            model_config = json.load(f)
        
        print("æ¨¡å‹éªŒè¯æˆåŠŸ!")
        print(f"  - æ¨¡å‹æ ¼å¼: {model_config.get('format', 'unknown')}")
        print(f"  - æƒé‡æ–‡ä»¶æ•°é‡: {len(weight_files)}")
        print(f"  - æƒé‡æ–‡ä»¶: {', '.join(weight_files)}")
        
        return True
        
    except Exception as e:
        print(f"è¯»å–æ¨¡å‹é…ç½®å¤±è´¥: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description='è½¬æ¢PyTorchæ¨¡å‹ä¸ºTensorFlow.jsæ ¼å¼')
    parser.add_argument('--model_path', type=str, 
                       default='../public/models/resnet18_identity/resnet18_identity.pth',
                       help='PyTorchæ¨¡å‹è·¯å¾„')
    parser.add_argument('--output_path', type=str, 
                       default='../public/models/resnet18_identity',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--temp_dir', type=str, 
                       default='./temp_conversion',
                       help='ä¸´æ—¶æ–‡ä»¶ç›®å½•')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.model_path):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {args.model_path}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_path, exist_ok=True)
    os.makedirs(args.temp_dir, exist_ok=True)
    
    print("=== ResNet18æ¨¡å‹è½¬æ¢ ===")
    print(f"è¾“å…¥æ¨¡å‹: {args.model_path}")
    print(f"è¾“å‡ºç›®å½•: {args.output_path}")
    
    try:
        # 1. åŠ è½½PyTorchæ¨¡å‹
        print("\næ­¥éª¤1: åŠ è½½PyTorchæ¨¡å‹")
        model, class_names = load_pytorch_model(args.model_path)
        print(f"åŠ è½½æˆåŠŸ! ç±»åˆ«æ•°: {len(class_names)}")
        print(f"ç±»åˆ«: {class_names}")
        
        # 2. è½¬æ¢ä¸ºONNX
        print("\næ­¥éª¤2: è½¬æ¢ä¸ºONNXæ ¼å¼")
        onnx_path = os.path.join(args.temp_dir, 'model.onnx')
        convert_to_onnx(model, onnx_path)
        
        # 3. è½¬æ¢ä¸ºTensorFlow
        print("\næ­¥éª¤3: è½¬æ¢ä¸ºTensorFlowæ ¼å¼")
        tf_path = os.path.join(args.temp_dir, 'tf_model')
        if not convert_onnx_to_tensorflow(onnx_path, tf_path):
            print("TensorFlowè½¬æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥onnx-tfæ˜¯å¦æ­£ç¡®å®‰è£…")
            return
        
        # 4. è½¬æ¢ä¸ºTensorFlow.js
        print("\næ­¥éª¤4: è½¬æ¢ä¸ºTensorFlow.jsæ ¼å¼")
        if not convert_to_tfjs(tf_path, args.output_path):
            print("TensorFlow.jsè½¬æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥tensorflowjsæ˜¯å¦æ­£ç¡®å®‰è£…")
            return
        
        # 5. åˆ›å»ºå…ƒæ•°æ®
        print("\næ­¥éª¤5: åˆ›å»ºæ¨¡å‹å…ƒæ•°æ®")
        create_model_metadata(class_names, args.output_path)
        
        # 6. éªŒè¯æ¨¡å‹
        print("\næ­¥éª¤6: éªŒè¯è½¬æ¢ç»“æœ")
        if validate_tfjs_model(args.output_path):
            print("\nğŸ‰ æ¨¡å‹è½¬æ¢æˆåŠŸ!")
            print(f"TensorFlow.jsæ¨¡å‹å·²ä¿å­˜åˆ°: {args.output_path}")
            print("\nç°åœ¨å¯ä»¥åœ¨Webåº”ç”¨ä¸­ä½¿ç”¨è¯¥æ¨¡å‹äº†!")
        else:
            print("\nâŒ æ¨¡å‹éªŒè¯å¤±è´¥")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        print(f"\næ¸…ç†ä¸´æ—¶æ–‡ä»¶: {args.temp_dir}")
        import shutil
        shutil.rmtree(args.temp_dir, ignore_errors=True)
        
    except Exception as e:
        print(f"\nè½¬æ¢è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
