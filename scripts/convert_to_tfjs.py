#!/usr/bin/env python3
"""
æ¨¡å‹è½¬æ¢è„šæœ¬ï¼šPyTorch â†’ TensorFlow.js
å°†è®­ç»ƒå¥½çš„ResNet18æ¨¡å‹è½¬æ¢ä¸ºWebå¯ç”¨çš„TensorFlow.jsæ ¼å¼
"""

import os
import sys
import torch
import torch.nn as nn
import torchvision.models as models
import json
import subprocess
import argparse
from pathlib import Path

def load_pytorch_model(model_path, num_classes=10):
    """åŠ è½½PyTorchæ¨¡å‹"""
    
    # åˆ›å»ºæ¨¡å‹ç»“æ„
    model = models.resnet18(pretrained=False)
    num_features = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Dropout(0.5),
        nn.Linear(num_features, 256),
        nn.ReLU(),
        nn.Dropout(0.3),
        nn.Linear(256, num_classes)
    )
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(model_path, map_location='cpu')
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    return model, checkpoint.get('class_names', [f'ID_{i+1}' for i in range(num_classes)])

def convert_to_onnx(model, onnx_path):
    """è½¬æ¢ä¸ºONNXæ ¼å¼"""
    
    print("æ­£åœ¨è½¬æ¢ä¸ºONNXæ ¼å¼...")
    
    # åˆ›å»ºè™šæ‹Ÿè¾“å…¥
    dummy_input = torch.randn(1, 3, 224, 224)
    
    # å¯¼å‡ºONNX
    torch.onnx.export(
        model,
        dummy_input,
        onnx_path,
        export_params=True,
        opset_version=11,
        do_constant_folding=True,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={
            'input': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        }
    )
    
    print(f"ONNXæ¨¡å‹å·²ä¿å­˜åˆ°: {onnx_path}")

def convert_to_tensorflow(onnx_path, tf_path):
    """è½¬æ¢ONNXåˆ°TensorFlow"""
    
    print("æ­£åœ¨è½¬æ¢ONNXåˆ°TensorFlow...")
    
    try:
        # ä½¿ç”¨onnx-tfè½¬æ¢
        cmd = f"onnx-tf convert -i {onnx_path} -o {tf_path}"
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"è½¬æ¢å¤±è´¥: {result.stderr}")
            return False
            
        print(f"TensorFlowæ¨¡å‹å·²ä¿å­˜åˆ°: {tf_path}")
        return True
        
    except Exception as e:
        print(f"è½¬æ¢è¿‡ç¨‹å‡ºé”™: {e}")
        return False

def convert_to_tfjs(tf_path, tfjs_path):
    """è½¬æ¢TensorFlowåˆ°TensorFlow.js"""
    
    print("æ­£åœ¨è½¬æ¢åˆ°TensorFlow.jsæ ¼å¼...")
    
    try:
        # ä½¿ç”¨tensorflowjs_converterè½¬æ¢
        cmd = f"tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model --quantize_float16 {tf_path} {tfjs_path}"
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"è½¬æ¢å¤±è´¥: {result.stderr}")
            return False
            
        print(f"TensorFlow.jsæ¨¡å‹å·²ä¿å­˜åˆ°: {tfjs_path}")
        return True
        
    except Exception as e:
        print(f"è½¬æ¢è¿‡ç¨‹å‡ºé”™: {e}")
        return False

def create_model_metadata(class_names, tfjs_path):
    """åˆ›å»ºæ¨¡å‹å…ƒæ•°æ®"""
    
    metadata = {
        "model_name": "ResNet18 Identity Classifier",
        "model_version": "1.0.0",
        "description": "åŸºäºResNet18çš„å…»è€é™¢èº«ä»½è¯†åˆ«åˆ†ç±»å™¨",
        "input_shape": [1, 224, 224, 3],
        "output_shape": [1, len(class_names)],
        "num_classes": len(class_names),
        "class_names": class_names,
        "class_mapping": {i: name for i, name in enumerate(class_names)},
        "preprocessing": {
            "resize": [224, 224],
            "normalize": {
                "mean": [0.485, 0.456, 0.406],
                "std": [0.229, 0.224, 0.225]
            }
        },
        "usage": {
            "strict_consistency_check": True,
            "required_images": 3,
            "confidence_threshold": 0.7,
            "time_permissions": {
                "staff": "24h",
                "resident": "06:30-20:30"
            }
        }
    }
    
    # ä¿å­˜å…ƒæ•°æ®
    metadata_path = os.path.join(tfjs_path, 'metadata.json')
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    print(f"æ¨¡å‹å…ƒæ•°æ®å·²ä¿å­˜åˆ°: {metadata_path}")

def validate_tfjs_model(tfjs_path):
    """éªŒè¯TensorFlow.jsæ¨¡å‹"""
    
    print("æ­£åœ¨éªŒè¯TensorFlow.jsæ¨¡å‹...")
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    required_files = ['model.json']
    for file_name in required_files:
        file_path = os.path.join(tfjs_path, file_name)
        if not os.path.exists(file_path):
            print(f"é”™è¯¯: ç¼ºå°‘æ–‡ä»¶ {file_name}")
            return False
    
    # æ£€æŸ¥æƒé‡æ–‡ä»¶
    weight_files = [f for f in os.listdir(tfjs_path) if f.endswith('.bin')]
    if not weight_files:
        print("é”™è¯¯: ç¼ºå°‘æƒé‡æ–‡ä»¶ (.bin)")
        return False
    
    # è¯»å–æ¨¡å‹é…ç½®
    model_json_path = os.path.join(tfjs_path, 'model.json')
    try:
        with open(model_json_path, 'r') as f:
            model_config = json.load(f)
        
        print("æ¨¡å‹éªŒè¯æˆåŠŸ!")
        print(f"  - æ¨¡å‹æ ¼å¼: {model_config.get('format', 'unknown')}")
        print(f"  - æƒé‡æ–‡ä»¶æ•°é‡: {len(weight_files)}")
        print(f"  - æƒé‡æ–‡ä»¶: {', '.join(weight_files)}")
        
        return True
        
    except Exception as e:
        print(f"è¯»å–æ¨¡å‹é…ç½®å¤±è´¥: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description='è½¬æ¢PyTorchæ¨¡å‹ä¸ºTensorFlow.jsæ ¼å¼')
    parser.add_argument('--model_path', type=str, 
                       default='../public/models/resnet18_identity/resnet18_identity.pth',
                       help='PyTorchæ¨¡å‹è·¯å¾„')
    parser.add_argument('--output_path', type=str, 
                       default='../public/models/resnet18_identity',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--temp_dir', type=str, 
                       default='./temp_conversion',
                       help='ä¸´æ—¶æ–‡ä»¶ç›®å½•')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.model_path):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {args.model_path}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_path, exist_ok=True)
    os.makedirs(args.temp_dir, exist_ok=True)
    
    print("=== ResNet18æ¨¡å‹è½¬æ¢ ===")
    print(f"è¾“å…¥æ¨¡å‹: {args.model_path}")
    print(f"è¾“å‡ºç›®å½•: {args.output_path}")
    
    try:
        # 1. åŠ è½½PyTorchæ¨¡å‹
        print("\næ­¥éª¤1: åŠ è½½PyTorchæ¨¡å‹")
        model, class_names = load_pytorch_model(args.model_path)
        print(f"åŠ è½½æˆåŠŸ! ç±»åˆ«æ•°: {len(class_names)}")
        print(f"ç±»åˆ«: {class_names}")
        
        # 2. è½¬æ¢ä¸ºONNX
        print("\næ­¥éª¤2: è½¬æ¢ä¸ºONNXæ ¼å¼")
        onnx_path = os.path.join(args.temp_dir, 'model.onnx')
        convert_to_onnx(model, onnx_path)
        
        # 3. è½¬æ¢ä¸ºTensorFlow
        print("\næ­¥éª¤3: è½¬æ¢ä¸ºTensorFlowæ ¼å¼")
        tf_path = os.path.join(args.temp_dir, 'tf_model')
        if not convert_to_tensorflow(onnx_path, tf_path):
            print("TensorFlowè½¬æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥onnx-tfæ˜¯å¦æ­£ç¡®å®‰è£…")
            return
        
        # 4. è½¬æ¢ä¸ºTensorFlow.js
        print("\næ­¥éª¤4: è½¬æ¢ä¸ºTensorFlow.jsæ ¼å¼")
        if not convert_to_tfjs(tf_path, args.output_path):
            print("TensorFlow.jsè½¬æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥tensorflowjsæ˜¯å¦æ­£ç¡®å®‰è£…")
            return
        
        # 5. åˆ›å»ºå…ƒæ•°æ®
        print("\næ­¥éª¤5: åˆ›å»ºæ¨¡å‹å…ƒæ•°æ®")
        create_model_metadata(class_names, args.output_path)
        
        # 6. éªŒè¯æ¨¡å‹
        print("\næ­¥éª¤6: éªŒè¯è½¬æ¢ç»“æœ")
        if validate_tfjs_model(args.output_path):
            print("\nğŸ‰ æ¨¡å‹è½¬æ¢æˆåŠŸ!")
            print(f"TensorFlow.jsæ¨¡å‹å·²ä¿å­˜åˆ°: {args.output_path}")
            print("\nç°åœ¨å¯ä»¥åœ¨Webåº”ç”¨ä¸­ä½¿ç”¨è¯¥æ¨¡å‹äº†!")
        else:
            print("\nâŒ æ¨¡å‹éªŒè¯å¤±è´¥")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        print(f"\næ¸…ç†ä¸´æ—¶æ–‡ä»¶: {args.temp_dir}")
        import shutil
        shutil.rmtree(args.temp_dir, ignore_errors=True)
        
    except Exception as e:
        print(f"\nè½¬æ¢è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
